Если хочется проверить результат - копируем скрипты и массивы в одну директорию и запускаем pipeline.py.
filter_funding_rows.py фильтрует только строки с фандингом, validate_data.py проверяет данные на ошибки, filter_om_funding.py из полученных строк фильтрует только OM, calculate_om_funding_totals.py считает.

Я решил вынести проверку данных на ошибки в отдельный скрипт. Ставить проверку в рабочий код мне показалось слишком громоздким. Мы проверяем не весь датасет, а только тот, что произведен filter_funding_rows.py, потому что нам не нужно, чтобы каждая строка изначального массива соответствовала формату, который необходим для проверки фандинга. Я вижу одну проблему, связанную с таким подходом: строки, которые соответствуют funding fees, могли не затянуться, потому что у них и type_exchange не фандинг, и type_id не 405. Мне кажется, что это уже out of scope для этой задачи, потому что тут фокус смещается на то чтобы найти ошибки в данных, а не посчитать что-то. Я осуществил базовую осмотрительность, но в целом воспринимал данные как истину и специально ошибок не искал.

Мой результат:

| Exchange    | Paid      | Rows | Received  | Rows | Net         |
|-------------|-----------|------|-----------|------|-------------|
| Binance     | 2799.0310 | 194  | 490.5405  | 85   | -2308.4905  |
| Bybit       | 634.9941  | 104  | 13.8055   | 11   | -621.1886   |
| Cryptocom   | 347.6600  | 104  | 319.2969  | 150  | -28.3632    |
| ME.HitBTC   | 0.0000    | 0    | 0.1232    | 27   | 0.1232      |
| Okex        | 190.4377  | 110  | 260.5843  | 61   | 70.1467     |
| Paradex     | 0.1654    | 60   | 0.9564    | 34   | 0.7910      |
| **TOTAL**   | **3972.2883** | **572** | **1085.3068** | **368** | **-2886.9815** |

